{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helloKH/Psypy/blob/master/Psypy2_handson_CH1The%20Machine%20Learning%20Landscape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri7UWbxpYUPb",
        "colab_type": "code",
        "outputId": "bf29a7d1-5d35-4cbc-a417-8bb0fd6da728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/helloKH/Psypy.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Psypy'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/36)\u001b[K\rremote: Counting objects:   5% (2/36)\u001b[K\rremote: Counting objects:   8% (3/36)\u001b[K\rremote: Counting objects:  11% (4/36)\u001b[K\rremote: Counting objects:  13% (5/36)\u001b[K\rremote: Counting objects:  16% (6/36)\u001b[K\rremote: Counting objects:  19% (7/36)\u001b[K\rremote: Counting objects:  22% (8/36)\u001b[K\rremote: Counting objects:  25% (9/36)\u001b[K\rremote: Counting objects:  27% (10/36)\u001b[K\rremote: Counting objects:  30% (11/36)\u001b[K\rremote: Counting objects:  33% (12/36)\u001b[K\rremote: Counting objects:  36% (13/36)\u001b[K\rremote: Counting objects:  38% (14/36)\u001b[K\rremote: Counting objects:  41% (15/36)\u001b[K\rremote: Counting objects:  44% (16/36)\u001b[K\rremote: Counting objects:  47% (17/36)\u001b[K\rremote: Counting objects:  50% (18/36)\u001b[K\rremote: Counting objects:  52% (19/36)\u001b[K\rremote: Counting objects:  55% (20/36)\u001b[K\rremote: Counting objects:  58% (21/36)\u001b[K\rremote: Counting objects:  61% (22/36)\u001b[K\rremote: Counting objects:  63% (23/36)\u001b[K\rremote: Counting objects:  66% (24/36)\u001b[K\rremote: Counting objects:  69% (25/36)\u001b[K\rremote: Counting objects:  72% (26/36)\u001b[K\rremote: Counting objects:  75% (27/36)\u001b[K\rremote: Counting objects:  77% (28/36)\u001b[K\rremote: Counting objects:  80% (29/36)\u001b[K\rremote: Counting objects:  83% (30/36)\u001b[K\rremote: Counting objects:  86% (31/36)\u001b[K\rremote: Counting objects:  88% (32/36)\u001b[K\rremote: Counting objects:  91% (33/36)\u001b[K\rremote: Counting objects:  94% (34/36)\u001b[K\rremote: Counting objects:  97% (35/36)\u001b[K\rremote: Counting objects: 100% (36/36)\u001b[K\rremote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 343 (delta 19), reused 0 (delta 0), pack-reused 307\u001b[K\n",
            "Receiving objects: 100% (343/343), 3.65 MiB | 8.95 MiB/s, done.\n",
            "Resolving deltas: 100% (181/181), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lHI_h26Zdcn",
        "colab_type": "code",
        "outputId": "2b51ddfc-9f79-4695-8d3c-2a6537b5e960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls -ltr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Dec 18 16:52 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4096 Jan  1 22:17 \u001b[01;34mPsypy\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVw1d2-hYeEm",
        "colab_type": "code",
        "outputId": "2a2a015c-51e7-4f79-d45c-acf2878eba23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!ls Psypy/image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Figure 1-10.png'  'Figure 1-16.png'  'Figure 1-21.png'  'Figure 1-5.png'\n",
            "'Figure 1-11.png'  'Figure 1-17.png'  'Figure 1-22.png'  'Figure 1-6.png'\n",
            "'Figure 1-12.png'  'Figure 1-18.png'  'Figure 1-23.png'  'Figure 1-7.png'\n",
            "'Figure 1-13.png'  'Figure 1-19.png'  'Figure 1-2.png'\t 'Figure 1-8.png'\n",
            "'Figure 1-14.png'  'Figure 1-1.png'   'Figure 1-3.png'\t 'Figure 1-9.png'\n",
            "'Figure 1-15.png'  'Figure 1-20.png'  'Figure 1-4.png'\t  Read.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1E4tHPGYU54",
        "colab_type": "text"
      },
      "source": [
        "### Psypy2 1회차\n",
        "#### 교재: Hands on Machine Learning with Scikit-Learn, Keras & TensorFlow\n",
        "#### Part1. The Fundamentals of Machine Learning\n",
        "##### CH1. The Machine Learning Landscape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ9amP37YXMF",
        "colab_type": "text"
      },
      "source": [
        "#### Chapter1 목적\n",
        "- 모든 데이터 과학자가 알아야 하는 기본 개념 소개"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lenFcjT-YZi7",
        "colab_type": "text"
      },
      "source": [
        "### What Is Machine Learning?\n",
        "- Machine Learning is the science (and art) of programming computers so they can learn from data.\n",
        "\n",
        "- general definition  \n",
        "[Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed.  \n",
        "— Arthur Samuel, 1959\n",
        "\n",
        "\n",
        "- engineering  \n",
        "A computer program is said to learn from experience E with respect to some task Tand some performance measure P, if its performance on T, as measured by P, improves with experience E.  \n",
        "—Tom Mitchell, 1997"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClzzSMrFm0fo",
        "colab_type": "text"
      },
      "source": [
        "### Why Use Machine Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr2wbXwQYbgy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### 1. 일반적인 스팸 분류 방법과 절차(그림1)\n",
        "\n",
        "\n",
        "![Figure1-1](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-1.png)\n",
        "\n",
        "1. 스팸 메일은 일반적으로 일부 문구(“4U,” “credit card,” “free,” and “amazing”)를 포함\n",
        "2. 발견 한 각 패턴에 대해 탐지 알고리즘을 작성하고 이러한 패턴이 다수 감지되면 프로그램은 이메일을 스팸으로 표시.\n",
        "3.  프로그램을 테스트하고 충분할 때까지 1 단계와 2 단계를 반복.\n",
        "\n",
        "#### 2. ML을 이용한 스팸 분류 방법과 절차(그림2)\n",
        "\n",
        "![Figure1-2](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-1.png)\n",
        "\n",
        "반대로 Machine Learning 기술을 기반의 스팸 필터는 스팸 예시에서 비정상적으로 빈번한 단어 패턴을 감지, 어떤 단어와 구가 스팸을 예측하는 좋은지 자동으로 학습 (그림 1-2).\n",
        "\n",
        "#### 3. 분류기 자동화(그림3) \n",
        "\n",
        "![Figure1-3](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-3.png)\n",
        "\n",
        "또한 “For U”와 같은 단어가 빈번하게 발생하면, 사용자의 지정 없이도 해당 단어를 스팸 분류기에 포함할 수 있음\n",
        "\n",
        "#### 4. 인간 학습에 도움을 주는 머신러닝(그림4)\n",
        "\n",
        "![Figure1-4](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-4.png)\n",
        "\n",
        "ML 알고리즘을 통한 학습은 인간이 의심하지 못한 상관관계나 새로운 경향을 보여줄 때가 있음. 이는 해당 문제를 더 잘 이해하게 도울 수 있다.\n",
        "\n",
        "\n",
        "요약하자면, 머신러닝은 아래와 같은 이점을 제공  \n",
        "* 기존 솔루션에 많은 수동 조정 또는 긴 규칙 목록이 필요한 문제 : 하나의 머신 러닝 알고리즘으로 종종 코드를 단순화하고 성능을 향상.  \n",
        "* 전통적인 방법을 사용하여 좋은 해결책이 전혀없는 복잡한 문제 : 머신 러닝 기술로 해결책 발견 가능  \n",
        "* 변동하는 환경 : 머신 러닝 시스템은 새로운 데이터에 적응 가능  \n",
        "* 복잡한 문제와 많은 양의 데이터에 대한 통찰력 제공 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsfCr1uG9Ywn",
        "colab_type": "text"
      },
      "source": [
        "### Types of Machine Learning Systems\n",
        "\n",
        "분류하는 몇 가지 기준 존재\n",
        "\n",
        "* 인간 감독 훈련을 받았는지 여부 (지도학습, 비지도학습, 반지도학습 및 강화학습)  \n",
        "* 즉석에서 점진적으로 학습 할 수 있는지 여부 (online vs batch learning)  \n",
        "* 과학자들이 하는 것처럼 새로운 데이터 포인트를 알려진 데이터 포인트와 단순히 비교하거나 대신 훈련 데이터의 패턴을 감지하고 예측 모델을 구축하여 작업하는지 여부 (instance-based versus model-based learning)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyNMaVsiW1Tf",
        "colab_type": "text"
      },
      "source": [
        "#### Supervised/Unsupervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E9l_oEx_XI_",
        "colab_type": "text"
      },
      "source": [
        "##### 1. Supervised learning\n",
        "\n",
        "알고리즘에 제공하는 training data에 label이라 불리는, solutions이 포함됨\n",
        "\n",
        "(1) classification  \n",
        "\n",
        "![Figure1-5](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-5.png)\n",
        "\n",
        "일반적인 지도학습의 예시는 분류(classification). 스팸 분류 사례 참고\n",
        "class (spam or ham)가 포함된 예제를 학습하면서, 새로운 대상이 스팸인지 아닌지를 분류한다.\n",
        "\n",
        "(2) Regression\n",
        "\n",
        "![Figure1-6](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-6.png)\n",
        "\n",
        "마일리지, 연령 등 숫자 값을 예측하는 경우, 회귀(Regression)라고 함.   \n",
        "training data에는 label(ex-가격)과 예측 변수(predictors)가 모두 포함됨\n",
        "\n",
        "* 단, 일부 회귀 모형 알고리즘(Logistic Regression 등)은 분류에 사용 가능\n",
        "\n",
        "\n",
        "이 책에서 다루는 강화학습의 주요 알고리즘은 아래와 같음\n",
        "* k-Nearest Neighbors\n",
        "* Linear Regression\n",
        "* Logistic Regression\n",
        "* Support Vector Machines (SVMs)\n",
        "* Decision Trees and Random Forests\n",
        "* Neural networks2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3ZYiAu2WyxE",
        "colab_type": "text"
      },
      "source": [
        "##### 2. Unsupervised learning\n",
        "\n",
        "![Figure1-7](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-7.png)\n",
        "\n",
        "학습(정답 label) 없이 진행되는 시스템\n",
        "\n",
        "가장 중요한 비지도학습 알고리즘은 아래와 같음(Chapter 8 & 9)\n",
        "* Clustering\n",
        "  - K-Means\n",
        "  - DBSCAN\n",
        "  - Hierarchical Cluster Analysis (HCA)\n",
        "* Anomaly detection and novelty detection\n",
        "  - One-class SVM\n",
        "  - Isolation Forest\n",
        "* Visualization and dimensionality reduction\n",
        "  - Principal Component Analysis (PCA)\n",
        "  - Kernel PCA\n",
        "  - Locally-Linear Embedding (LLE)\n",
        "  - t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
        "* Association rule learning\n",
        "  - Apriori\n",
        "  - Eclat\n",
        "\n",
        "\n",
        "(1) Clustering: 블로그 방문자 분석 예시  \n",
        "![Figure1-8](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-8.png)\n",
        "\n",
        "블로그 방문자에 대한 클러스터링 진행 가능. hierarchical clustering algorithm 등으로 세분화를 할 경우, 각 집단의 게시물을 타겟팅하는데 도움이 된다.\n",
        "\n",
        "(2) Visualization  \n",
        "![Figure1-9](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-9.png)\n",
        "\n",
        "complex and unlabeled data에 대해 2D or 3D representation을 출력\n",
        "\n",
        "시각화 알고리즘은 가능한 한 많은 구조를 유지하려고 함(예 : 입력 공간에서 별도의 클러스터를 시각화에서 겹치지 않도록 유지하려고 시도함). 따라서 데이터의 구성 방식을 이해하고 의심되지 않는 패턴을 식별할 수 있다.\n",
        "\n",
        "차원 축소(dimensionality reduction)는 이와 관련되는 작업으로, 너무 많은 데이터 손실 없이 데이터를 단순화하는 것을 일컫음. 이를 수행하는 방법으로 기능추출(feature extraction)이 존재\n",
        "- 예) 자동차의 주행 거리는 나이와 관련이 있기 때문에, 이 2가지를 자동차의 마모를 나타내는 기능으로 병합함\n",
        "\n",
        "(3) 이상 탐지(anomaly detection)\n",
        "\n",
        "신용 카드에서 사기 거래 감지, 제조 결함 포착 등.  \n",
        "![Figure1-10](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-10.png)\n",
        "\n",
        "시스템은 training 과정에서 정상 사례(normal instances)를 학습하고, 새 instances가 들어올 때 그것의 정상/비정상 여부를 판단 \n",
        "새로움 탐지(novelty detection) 역시 비슷한 과정. 단 novelty detection는 training 중에 정상적인 데이터만 예상하는 반면, 이상탐지 알고리즘은 적은 비율의 이상치로도 우수한 성능 가능. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKbRYDVtwa3M",
        "colab_type": "text"
      },
      "source": [
        "##### 3. Semisupervised learning\n",
        "\n",
        "몇몇 알고리즘은 부분적으로는 label이 있는 training data를 사용함과 동시에  unlabeled data도 사용 가능.(그림 1-11).\n",
        "\n",
        "![Figure1-11](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-11.png)\n",
        "\n",
        "- 예) 구글 photo와 같은 사진 호스팅 서비스\n",
        "- 모든 가족 사진을 서비스에 업로드하면 동일한 사람 A가 사진 1, 5 및 11에 표시되고 다른 사람 B가 사진 2, 5 및 7에 표시되는 것을 자동으로 인식하게 됨(지도되지 않은 부분, 클러스터링). 이후 한 사람당 하나의 레이블로 모든 사진의 모든 사람의 이름을 지정하여 검색하게 함.\n",
        "\n",
        "대부분의 Semisupervised learning는 지도학습과 비지도학습 알고리즘의 조합임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCaodpJM43aT",
        "colab_type": "text"
      },
      "source": [
        "##### 4. Reinforcement Learning\n",
        "\n",
        "![Figure1-12](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-12.png)\n",
        "\n",
        "- agent라 불리는 학습 시스템은 환경을 관찰할 수 있으며, 이후 action을 선택 및 수행한 후 그에 대한 보상(혹은 처벌)을 받음 \n",
        "\n",
        "ex) DeepMind’s AlphaGo program\n",
        "- 수백만 개의 게임을 분석한 후 자기 자신과 대결하며 스스로 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSrbEFJU5_Mz",
        "colab_type": "text"
      },
      "source": [
        "#### Batch and Online Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntZX2CDV6O69",
        "colab_type": "text"
      },
      "source": [
        "##### 1. Batch learning\n",
        "Batch learning은 점진적으로(incrementally) 학습할 수 없음. 사용 가능한 모든 데이터를 사용하여 학습해야 한다는 특징 존재. 많은 시간과 computing resource 요구.\n",
        "\n",
        "시스템 training 후 더 이상의 학습(learning) 없이 바로 투입되는 형태를 offline learning이라고 함.\n",
        "\n",
        "##### 2. Online learning\n",
        "\n",
        "Online learning에서는 데이터 instance를 개별적으로 혹은 소그룹(mini-batches)으로 순차적으로 공급하여 시스템을 점진적으로 훈련시킴. 각 학습 단계는 빠르고 저렴하므로 시스템은 새로운 데이터가 도착하자마자 즉시 학습 가능(그림 1-13).\n",
        "\n",
        "![Figure1-13](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-13.png)\n",
        "\n",
        "Online learning은 데이터를 지속적인 흐름(예 : 주가)으로 받고 빠르게/자율적으로 변화에 적응해야하는 시스템에 적합.\n",
        "\n",
        "computing resources가 제한될 경우, online learning system이 instance을 알게 되고 더 이상 필요 없다면 버릴 수 있음. 이는 엄청난 양의 공간을 절약함.\n",
        "\n",
        "![Figure1-14](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-14.png)\n",
        "\n",
        "온라인 학습 알고리즘을 사용하여 한 시스템의 기본 메모리에 맞지 않는 방대한 데이터 세트에 대한 시스템을 교육 할 수도 있다 (out-of-core learning). 알고리즘은 데이터의 일부를 load하고 해당 데이터에 대한 training step를 실행하며, 모든 데이터에서 실행될 때까지 프로세스를 반복한다(그림 1-14 참조).\n",
        "\n",
        "온라인 학습 시스템의 중요한 parameter는 학습 속도(learning rate)-변화하는 데이터에 얼마나 빨리 적응하느냐-임. \n",
        "- 높은 학습 속도 = 시스템이 새로운 데이터에 빠르게 적응하지만 이전 데이터를 빠르게 잊어 버린다(스팸 필터가 표시된 최신 스팸만 표시하고, 전체 스팸 필터를 원하지 않음) .\n",
        "- 낮은 학습 속도 = 시스템의 관성이 높아짐. 즉, 학습 속도가 느려지지만 새 데이터의 노이즈나 대표성이 없는 데이터포인트(이상치)의 시퀀스에 덜 민감함.\n",
        "\n",
        "온라인 학습의 가장 큰 문제는 잘못된 데이터가 시스템에 제공될 경우, 시스템 성능이 점차 저하된다는 것. 이 위험을 줄이려면 성능 저하가 감지될 때 시스템을 모니터링하고, 학습을 해제하고, 이전 상태로 되돌릴 수 있어야 한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCNhWliLa87Y",
        "colab_type": "text"
      },
      "source": [
        "#### Instance-Based Versus Model-Based Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXSXDVAGh3op",
        "colab_type": "text"
      },
      "source": [
        "##### 1. Instance-based learning\n",
        "\n",
        "시스템은 예제를 중심으로 학습한 다음 유사성 측정을 사용하여 학습된 예제(또는 subset)와 비교하여 새 사례로 일반화\n",
        "\n",
        "![Figure1-15](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-15.png)\n",
        "\n",
        "예를 들어 그림 1-15에서 가장 유사한 instance의 대부분이 삼각형 클래스에 속하므로 새 인스턴스는 삼각형으로 분류\n",
        "\n",
        "##### 2. Model-based learning\n",
        "\n",
        "![Figure1-16](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-16.png)\n",
        "\n",
        "예제의 모델을 형성한 후 해당 모델을 사용하여 예측을 진행\n",
        "\n",
        "![Figure1-17](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-17.png)\n",
        "\n",
        "예를 들어, 돈이 사람들을 행복하게하는지 알고 싶어서 OECD 웹 사이트에서 Better Life Index 데이터와 IMF 웹 사이트에서 1 인당 GDP에 대한 통계를 다운로드한다고 가정.\n",
        "\n",
        "국가의 1인당 GDP가 증가함에 따라 삶의 만족도가 선형적으로 증가하는 것처럼 보이므로, 1인당 GDP의 선형 함수로 삶의 만족도를 예측하는 모델 생성(model selection) 가능.\n",
        "\n",
        "1개의 속성(GDP per capita)으로 삶의 만족도를 예측하는 방정식:\n",
        "\n",
        "$$life  satisfaction = θ0 + θ1 × GDP per capita$$\n",
        "\n",
        "![Figure1-18](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-18.png)\n",
        "\n",
        "2개의 모델 파라미터(θ0 + θ1)로 선형함수를 표현 가능(그림 1-18)\n",
        "\n",
        "모델을 사용하기 전 parameter values인 θ0, θ1를 정의해야 함\n",
        "\n",
        "모델이 어떤 성능을 발휘할 수 있는지 알려면, 성능 측정 값(performance measure)을 지정해야 함) 또한 모델의 상태를 측정하는 효용성(utility) 기능(또는 적합성-fitness- 기능)을 정의하거나 모델의 상태를 측정하는 비용 함수를 정의할 수 있다.\n",
        "\n",
        "선형 회귀 문제의 경우 사람들은 일반적으로 선형 모형의 예측과 training examples 사이의 거리를 측정하여 비용함수로 사용. 거리의 최소화를 목표로 삼는다. \n",
        "\n",
        "training example를 제공하고 선형 모델을 데이터에 가장 적합하게 만드는 매개 변수를 찾는 과정을 모델 훈련(training the model)이라고 함. 이 사례의 경우 알고리즘의 최적의 파라미터 값이 θ0 = 4.85이고 θ1 = 4.91 × 10–5임을 발견할 수 있음.\n",
        "\n",
        "![Figure1-19](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-19.png)\n",
        "\n",
        "예측을 위해 모델 실행 가능. 키프로스 예시(1인당 GDP) 확인 후 모델에 투입\n",
        "- python code 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNG0tZKCZ9Gn",
        "colab_type": "text"
      },
      "source": [
        "##### Chapter1 요약\n",
        "\n",
        "ML 프로젝트는 아래와 같이 요약 가능\n",
        "- 데이터 연구\n",
        "- 모델 선택\n",
        "- 훈련 데이터를 통한 학습(trained it on the training data). 즉,학습 알고리즘이 비용 함수를 최소화하는 모델 parameter value를 search \n",
        "- 모델의 일반화를 위해 모델을 적용하여 새로운 사례를 예측(inference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hi5og3MXN--",
        "colab_type": "text"
      },
      "source": [
        "#### The Unreasonable Effectiveness of Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfCDVCxG5-D1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "![Figure1-20](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-20.png)\n",
        "\n",
        "2001 년에 발표된 유명한 논문에서 Microsoft 연구원인 Michele Banko와 Eric Brill은 상당히 간단한 알고리즘을 포함하여 매우 다른 머신 러닝 알고리즘이 충분한 데이터가 주어지면 자연어 명확성(disambiguation)의 복잡한 문제에서 거의 동일하게 잘 수행되었음을 보여줌, 그림 1-20 참조). 이는 알고리즘에 들이는 돈/시간과 corpus에 들이는 돈/시간 사이의 trade-off 관계를 고민하게 만듦.\n",
        "\n",
        "그러나 2009 년에 출판된 “데이터의 불합리한 효과”(“The Unreasonable Effectiveness of Data”)라는 제목의 논문에서, small & medium의 dataset는 여전히 흔하며 추가 training data를 얻는 것이 항상 쉽지 않거나 저렴한 것은 아니라는 것을 지적. 따라서 알고리즘의 이점을 쉽게 포기하면 안 됨."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lht5zrsa7WwM",
        "colab_type": "text"
      },
      "source": [
        "#### Nonrepresentative Training Data\n",
        "\n",
        "일반화를 위해선 training data가 새로운 case를 대표하는 것이 중요함. 그러나 그림 1-21처럼, 완벽하지 않은 데이터가 제공되는 경우도 있음\n",
        "\n",
        "![Figure1-21](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-21.png)\n",
        "\n",
        "이전 모델은 점선으로, 새 모형은 실선으로 표기됨\n",
        "몇 개 data가 누락되면 예측이 크게 변화함\n",
        "표본에서, 표본 수가 너무 작으면 sampling noise (i.e., 우연의 결과로서 비대표성을 갖는 데이터 습득)을 가지며, 표본 추출 방법에 결함이 있을 경우 표본이 대표성을 잃음. 이러한 경우를 표본 편향(sampling bias)라고 함 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yS7okAE9wkI",
        "colab_type": "text"
      },
      "source": [
        "#### Poor-Quality Data\n",
        "\n",
        "training data에 errors, outliers 및 noise가 가득 찬 경우 (예 : 저품질의 측정으로 인해) 시스템에서 기본 패턴을 감지하기가 어려워 성능이 저하될 수 있다. 이럴 경우 training data를 정리하는데 많은 시간을 할애하는 것이 좋다. 대부분의 데이터 과학자들은 데이터를 정리하는데 상당한 시간을 소비함 \n",
        "\n",
        "데이터 정리의 예) \n",
        "• 일부 instances가 outliers인 경우, 삭제하거나 오류를 손으로 수정하는 게 도움이 될 수 있음 \n",
        "• 일부 instances에 몇 가지 features가 누락된 경우 (예 : 고객의 5 %가 연령을 지정하지 않은 경우)이 features을 완전히 무시할지, 이러한 instances를 무시할지, 누락된 값을 채울지를 결정해야 함 (예 : 중간 연령 사용). 혹은 한 모델은 features 이 있는 것으로, 다른 하나는 features이 없는 것으로 학습 가능 \n",
        "\n",
        "#### Irrelevant Features\n",
        "\n",
        "시스템은 training data에 충분한 relevant features를 포함하고, irrelevant features가 너무 많지 않을 때 학습 가능함. 머신러닝 성공의 주요 이슈는 훈련할 수 있는 좋은 features를 제공하는 것\n",
        "\n",
        "feature engineering을 통해 feature를 고려할 수 있으며 아래 절차를 포함\n",
        "\n",
        "\n",
        "• 기능 선택(Feature selection) : 기존 feature 중에서 가장 유용한 기능을 선택.\n",
        "• 기능 추출(Feature extraction) : 기존 기능을 결합하여 보다 유용한 기능을 생성 (차원 축소 알고리즘-dimensionality reduction algorithms-이 도움이 될 수 있음).\n",
        "• 새로운 데이터를 수집하여 새로운 feature 생성\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ36E97fK-yy",
        "colab_type": "text"
      },
      "source": [
        "#### 잘못된 알고리즘들의 예시"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8v6oZRuAXTV",
        "colab_type": "text"
      },
      "source": [
        "1. Overfitting the Training Data\n",
        "\n",
        "![Figure1-22](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-22.png)\n",
        "\n",
        "모델이 Training data에서는 잘 수행되지만 일반화는 되지 않는 것\n",
        "그림 1-22는 training data를 넘어서는 고차 다항식 모형(high-degree polynomial life satisfaction model)을 보여줌\n",
        "\n",
        "심층 신경망(deep neural networks)과 같은 복잡한 모델은 데이터에서 미묘한 패턴을 감지할 수 있지만, training set에 noise가 있거나 너무 작아 sampling noise가 발생하는 경우, noise 그 자체의 패턴을 발견할 수 있다. 이러한 패턴은 새 instances로 일반화되지 않는다.\n",
        "  - 예) 삶의 만족도 모델에 국가명과 같은 유익하지 않은 feature를 포함하여 더 많은 feature을 제공한다고 가정해보자. 이 경우 복잡한 모델은 이름이 w 인 training data의 모든 국가의 삶의 만족도가 7보다 크다는 패턴을 감지한다-New Zealand (7.3), Norway (7.4), Sweden (7.2), and Switzerland (7.5)-. \n",
        "  - 그러나 이 모델이 Rwanda or Zimbabwe에도 일반화될 것인가?\n",
        "  - 분명 training data로만 학습했지만, 이것만으로는 패턴이 실제를 반영하는지 noise의 결과값인지 알기 어렵다\n",
        "\n",
        "모델을 단순화하고 overfitting의 위험을 줄이는 과정을 정규화(regularization)라고 함\n",
        "  - 예) 현재 회귀선형 모델에는 height (θ0) and the slope (θ1) 라는 parameter로 자유도를 조정할 수 있음. θ1 = 0로 강제한다면, 자유도를 1개로 고정할 수 있음.\n",
        "\n",
        "![Figure1-23](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-23.png)\n",
        "\n",
        "그림 1-23은 세 가지 모델을 보여줌. \n",
        "\n",
        "*   점선(dotted line): 몇 개 국가가 누락된 원래 모델\n",
        "*   2번째 점선(dashed line):  모든 국가가 training된 모델\n",
        "*   실선(solid line): 첫 번째 모형에 정규화를 도입한 모델  \n",
        "\n",
        "\n",
        "정규화로 인해 모델의 기울기가 더 작아져 모델이 학습된 training data가 약간 더 적어졌지만, 실제로는 새 instances에 더 잘 일반화 할 수 있다.\n",
        "\n",
        "학습 중에 적용 할 정규화의 양은 하이퍼 파라미터(hyperparameter)로 제어 할 수 있다. 하이퍼 파라미터란 학습 알고리즘의 매개 변수이다(모델이 아님).  하이퍼 파라미터 튜닝은 머신 러닝 시스템 구축의 중요한 부분이며, 다음 장에서 자세히 다룰 예정임 \n",
        "\n",
        "2. Underfitting the Training Data\n",
        "\n",
        "Underfitting은 Overfitting과 반대 개념. 모델이 데이터의 기본 구조를 배우기에 너무 단순할 때 발생. 예를 들어, 삶의 만족도의 선형 모델은 적합하지 않은 경향이 있음(현실은 모델보다 훨씬 복잡하므로 training examples에서도 예측이 정확하지 않음)\n",
        "\n",
        "이 문제를 해결하기 위한 주요 옵션은 아래와 같음 \n",
        "* 더 많은 매개 변수를 사용하여 더 강력한 모델 선택\n",
        "* 학습 알고리즘에 더 나은 feature 제공 (피처 엔지니어링)\n",
        "* 모델의 제약 조건을 줄임 (예 : 정규화 hyperparameter 감소).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAwjo2v0PJem",
        "colab_type": "text"
      },
      "source": [
        "#### Testing and Validating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NySs_EBNLC_q",
        "colab_type": "text"
      },
      "source": [
        "일반적으로 training set 과 the test set을 분리\n",
        "\n",
        "1. Hyperparameter Tuning and Model Selection\n",
        "\n",
        "모델을 평가할 때는 test set만 사용\n",
        "이후 overfitting을 피하기 위해 정규화 진행\n",
        "  - 정규화의 hyperparameter 값을 결정하는 것이 문제\n",
        "  - 한 가지 방법은 이 hyperparameter에 대해 100개의 서로 다른 값을 사용하여 100 개의 서로 다른 모델을 훈련시키는 것. 일반화 오류가 가장 적은 모델 (예 : 5 % 오류)을 생성하는 최상의 하이퍼 파라미터 값을 찾을 것 \n",
        "  - 그러나 testset에서 일반화 오류를 여러 번 측정하고 해당 set에 가장 적합한 모델을 생성하도록 모델 및 하이퍼 파라미터를 조정할 경우 문제가 발생. 모델이 새 데이터에서 잘 수행되지 않을 것이기 때문 \n",
        "  - 이 문제에 대한 일반적인 솔루션은 holdout validation: training set의 일부를 보류하여 여러 후보 모델을 평가하고, 가장 적합한 모델을 선택하는 것 \n",
        "\n",
        "2. Data Mismatch\n",
        "\n",
        "경우에 따라 training을 위해 많은 양의 데이터를 얻는 것이 쉽지만 그것이 production에 사용될 데이터를 완벽하게 나타내는 것은 아닐 때가 있다.\n",
        "  - 예를 들어 꽃 사진을 찍고 종을 자동으로 결정하는 모바일 앱을 만들고 싶다고 가정. 웹에서 수백만 장의 꽃 사진을 쉽게 다운로드 할 수 있지만 실제로 휴대 기기에서 앱을 사용하여 찍은 사진을 완벽하게 대표하지는 않음. \n",
        "  - 이 경우 기억해야 할 가장 중요한 규칙은 validation set와 test가 production 환경에서 사용할 것으로 예상되는 데이터를 가능한 한 대표해야하므로, validation set과 test set을 대표 사진으로만 구성해야한다는 것이다.\n",
        "  - 모델의 성능이 안 좋을 때, Overfitting과 Mismatch를 해결하는 한 가지 방법은 training image의 일부를 Andrew Ng가 train-dev 세트라고 부르는 또 다른 세트로 유지하는 것. (train-dev 세트가 아닌 학습 세트에서) 모델을 학습한 후 train-dev 세트에서 모델을 평가할 수 있다. \n",
        "  - 모델이 제대로 작동하면 모델이 training set에 Overfitting되지 않으므로, 성능이 저하될 시 validation set의 문제가 데이터 불일치로 인한 것이라고 볼 수 있다. 반대로 모델이 train-dev 세트에서 성능이 좋지 않으면 모델이 training set에 적합해야하므로 모델을 단순화 또는 정규화하고, 더 많은 훈련 데이터를 얻고, 데이터를 정리해야 한다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7stON6aBj0rJ",
        "colab_type": "text"
      },
      "source": [
        "# Code example 1-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETrfi76ZmF11",
        "colab_type": "text"
      },
      "source": [
        "**Chapter 1 – The Machine Learning landscape**\n",
        "\n",
        "_This is the code used to generate some of the figures in chapter 1._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6ohStz-mIOC",
        "colab_type": "text"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/01_the_machine_learning_landscape.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHIkASEYj3k6",
        "colab_type": "text"
      },
      "source": [
        "Although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqVWRMAZjuRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfcvdhrMj5fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK2_ThsYj9Cs",
        "colab_type": "text"
      },
      "source": [
        "This function just merges the OECD's life satisfaction data and the IMF's GDP per capita data. It's a bit too long and boring and it's not specific to Machine Learning, which is why I left it out of the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ben96JTj7FO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
        "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
        "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
        "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
        "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
        "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
        "                                  left_index=True, right_index=True)\n",
        "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
        "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
        "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
        "    return full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvJxIPPckCmT",
        "colab_type": "text"
      },
      "source": [
        "이 책의 코드는 데이터 파일이 현재 디렉토리에있을 것으로 예상하여 작성됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sv4qOPIkKPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "datapath = os.path.join(\"datasets\", \"lifesat\", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE2Ysa_zkONq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To plot pretty figures directly within Jupyter\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzKksv0QkP_y",
        "colab_type": "code",
        "outputId": "f4d07df3-ebbc-49fb-945a-ce862e53dc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Download the data\n",
        "import urllib\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "os.makedirs(datapath, exist_ok=True)\n",
        "for filename in (\"oecd_bli_2015.csv\", \"gdp_per_capita.csv\"):\n",
        "    print(\"Downloading\", filename)\n",
        "    url = DOWNLOAD_ROOT + \"datasets/lifesat/\" + filename\n",
        "    urllib.request.urlretrieve(url, datapath + filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading oecd_bli_2015.csv\n",
            "Downloading gdp_per_capita.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fM0SumTkRxs",
        "colab_type": "code",
        "outputId": "411fa1c9-e6f6-44d6-d857-d1abfa162617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "# Code example\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.linear_model\n",
        "\n",
        "# Load the data\n",
        "oecd_bli = pd.read_csv(datapath + \"oecd_bli_2015.csv\", thousands=',')\n",
        "gdp_per_capita = pd.read_csv(datapath + \"gdp_per_capita.csv\",thousands=',',delimiter='\\t',\n",
        "                             encoding='latin1', na_values=\"n/a\")\n",
        "\n",
        "# Prepare the data\n",
        "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
        "X = np.c_[country_stats[\"GDP per capita\"]]\n",
        "y = np.c_[country_stats[\"Life satisfaction\"]]\n",
        "\n",
        "# Visualize the data\n",
        "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
        "plt.show()\n",
        "\n",
        "# Select a linear model\n",
        "model = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make a prediction for Cyprus\n",
        "X_new = [[22587]]  # Cyprus' GDP per capita\n",
        "print(model.predict(X_new)) # outputs [[ 5.96242338]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAENCAYAAAD6/JlzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpmcJMzMLNN/AhhDzO+0BO+bAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[5.96242338]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5isS177k4-E",
        "colab_type": "text"
      },
      "source": [
        "# Load and prepare Life satisfaction data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzaCp4qjk7bj",
        "colab_type": "text"
      },
      "source": [
        "If you want, you can get fresh data from the OECD's website.\n",
        "Download the CSV from http://stats.oecd.org/index.aspx?DataSetCode=BLI\n",
        "and save it to `datasets/lifesat/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfL9mC3yk5ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oecd_bli = pd.read_csv(datapath + \"oecd_bli_2015.csv\", thousands=',')\n",
        "oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
        "oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
        "oecd_bli.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOwqwYK_k_8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oecd_bli[\"Life satisfaction\"].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjFCn_iHlE07",
        "colab_type": "text"
      },
      "source": [
        "Just like above, you can update the GDP per capita data if you want. Just download data from http://goo.gl/j1MSKe (=> imf.org) and save it to `datasets/lifesat/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftYZY6ZJlFON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdp_per_capita = pd.read_csv(datapath+\"gdp_per_capita.csv\", thousands=',', delimiter='\\t',\n",
        "                             encoding='latin1', na_values=\"n/a\")\n",
        "gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
        "gdp_per_capita.set_index(\"Country\", inplace=True)\n",
        "gdp_per_capita.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbQOVV5plHAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita, left_index=True, right_index=True)\n",
        "full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
        "full_country_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ylgY1plNsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_country_stats[[\"GDP per capita\", 'Life satisfaction']].loc[\"United States\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIo6g17llPYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
        "keep_indices = list(set(range(36)) - set(remove_indices))\n",
        "\n",
        "sample_data = full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]\n",
        "missing_data = full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[remove_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhyHp_6vlPwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_data.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction', figsize=(5,3))\n",
        "plt.axis([0, 60000, 0, 10])\n",
        "position_text = {\n",
        "    \"Hungary\": (5000, 1),\n",
        "    \"Korea\": (18000, 1.7),\n",
        "    \"France\": (29000, 2.4),\n",
        "    \"Australia\": (40000, 3.0),\n",
        "    \"United States\": (52000, 3.8),\n",
        "}\n",
        "for country, pos_text in position_text.items():\n",
        "    pos_data_x, pos_data_y = sample_data.loc[country]\n",
        "    country = \"U.S.\" if country == \"United States\" else country\n",
        "    plt.annotate(country, xy=(pos_data_x, pos_data_y), xytext=pos_text,\n",
        "            arrowprops=dict(facecolor='black', width=0.5, shrink=0.1, headwidth=5))\n",
        "    plt.plot(pos_data_x, pos_data_y, \"ro\")\n",
        "plt.xlabel(\"GDP per capita (USD)\")\n",
        "save_fig('money_happy_scatterplot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GceGfMNrlSUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_data.to_csv(os.path.join(\"datasets\", \"lifesat\", \"lifesat.csv\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsNNSokGlUGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_data.loc[list(position_text.keys())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20z3wuYblUWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sample_data.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction', figsize=(5,3))\n",
        "plt.xlabel(\"GDP per capita (USD)\")\n",
        "plt.axis([0, 60000, 0, 10])\n",
        "X=np.linspace(0, 60000, 1000)\n",
        "plt.plot(X, 2*X/100000, \"r\")\n",
        "plt.text(40000, 2.7, r\"$\\theta_0 = 0$\", fontsize=14, color=\"r\")\n",
        "plt.text(40000, 1.8, r\"$\\theta_1 = 2 \\times 10^{-5}$\", fontsize=14, color=\"r\")\n",
        "plt.plot(X, 8 - 5*X/100000, \"g\")\n",
        "plt.text(5000, 9.1, r\"$\\theta_0 = 8$\", fontsize=14, color=\"g\")\n",
        "plt.text(5000, 8.2, r\"$\\theta_1 = -5 \\times 10^{-5}$\", fontsize=14, color=\"g\")\n",
        "plt.plot(X, 4 + 5*X/100000, \"b\")\n",
        "plt.text(5000, 3.5, r\"$\\theta_0 = 4$\", fontsize=14, color=\"b\")\n",
        "plt.text(5000, 2.6, r\"$\\theta_1 = 5 \\times 10^{-5}$\", fontsize=14, color=\"b\")\n",
        "save_fig('tweaking_model_params_plot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgqDpHR5lW8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "lin1 = linear_model.LinearRegression()\n",
        "Xsample = np.c_[sample_data[\"GDP per capita\"]]\n",
        "ysample = np.c_[sample_data[\"Life satisfaction\"]]\n",
        "lin1.fit(Xsample, ysample)\n",
        "t0, t1 = lin1.intercept_[0], lin1.coef_[0][0]\n",
        "t0, t1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_jknNqwlYQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_data.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction', figsize=(5,3))\n",
        "plt.xlabel(\"GDP per capita (USD)\")\n",
        "plt.axis([0, 60000, 0, 10])\n",
        "X=np.linspace(0, 60000, 1000)\n",
        "plt.plot(X, t0 + t1*X, \"b\")\n",
        "plt.text(5000, 3.1, r\"$\\theta_0 = 4.85$\", fontsize=14, color=\"b\")\n",
        "plt.text(5000, 2.2, r\"$\\theta_1 = 4.91 \\times 10^{-5}$\", fontsize=14, color=\"b\")\n",
        "save_fig('best_fit_model_plot')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvCKnjFRlaGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cyprus_gdp_per_capita = gdp_per_capita.loc[\"Cyprus\"][\"GDP per capita\"]\n",
        "print(cyprus_gdp_per_capita)\n",
        "cyprus_predicted_life_satisfaction = lin1.predict([[cyprus_gdp_per_capita]])[0][0]\n",
        "cyprus_predicted_life_satisfaction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPDIE45slbeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_data.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction', figsize=(5,3), s=1)\n",
        "plt.xlabel(\"GDP per capita (USD)\")\n",
        "X=np.linspace(0, 60000, 1000)\n",
        "plt.plot(X, t0 + t1*X, \"b\")\n",
        "plt.axis([0, 60000, 0, 10])\n",
        "plt.text(5000, 7.5, r\"$\\theta_0 = 4.85$\", fontsize=14, color=\"b\")\n",
        "plt.text(5000, 6.6, r\"$\\theta_1 = 4.91 \\times 10^{-5}$\", fontsize=14, color=\"b\")\n",
        "plt.plot([cyprus_gdp_per_capita, cyprus_gdp_per_capita], [0, cyprus_predicted_life_satisfaction], \"r--\")\n",
        "plt.text(25000, 5.0, r\"Prediction = 5.96\", fontsize=14, color=\"b\")\n",
        "plt.plot(cyprus_gdp_per_capita, cyprus_predicted_life_satisfaction, \"ro\")\n",
        "save_fig('cyprus_prediction_plot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLasQwwZldf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_data[7:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD1jYdxnlfUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(5.1+5.7+6.5)/3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-RT0Asolg_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backup = oecd_bli, gdp_per_capita\n",
        "\n",
        "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
        "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
        "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
        "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
        "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
        "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
        "                                  left_index=True, right_index=True)\n",
        "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
        "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
        "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
        "    return full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmiGxbAtlhTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code example\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.linear_model\n",
        "\n",
        "# Load the data\n",
        "oecd_bli = pd.read_csv(datapath + \"oecd_bli_2015.csv\", thousands=',')\n",
        "gdp_per_capita = pd.read_csv(datapath + \"gdp_per_capita.csv\",thousands=',',delimiter='\\t',\n",
        "                             encoding='latin1', na_values=\"n/a\")\n",
        "\n",
        "# Prepare the data\n",
        "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
        "X = np.c_[country_stats[\"GDP per capita\"]]\n",
        "y = np.c_[country_stats[\"Life satisfaction\"]]\n",
        "\n",
        "# Visualize the data\n",
        "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
        "plt.show()\n",
        "\n",
        "# Select a linear model\n",
        "model = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make a prediction for Cyprus\n",
        "X_new = [[22587]]  # Cyprus' GDP per capita\n",
        "print(model.predict(X_new)) # outputs [[ 5.96242338]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWMGWQPGlkJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oecd_bli, gdp_per_capita = backup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59FA3286lkZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfUwclRXlm7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "position_text2 = {\n",
        "    \"Brazil\": (1000, 9.0),\n",
        "    \"Mexico\": (11000, 9.0),\n",
        "    \"Chile\": (25000, 9.0),\n",
        "    \"Czech Republic\": (35000, 9.0),\n",
        "    \"Norway\": (60000, 3),\n",
        "    \"Switzerland\": (72000, 3.0),\n",
        "    \"Luxembourg\": (90000, 3.0),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJcMO1pplnKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_data.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction', figsize=(8,3))\n",
        "plt.axis([0, 110000, 0, 10])\n",
        "\n",
        "for country, pos_text in position_text2.items():\n",
        "    pos_data_x, pos_data_y = missing_data.loc[country]\n",
        "    plt.annotate(country, xy=(pos_data_x, pos_data_y), xytext=pos_text,\n",
        "            arrowprops=dict(facecolor='black', width=0.5, shrink=0.1, headwidth=5))\n",
        "    plt.plot(pos_data_x, pos_data_y, \"rs\")\n",
        "\n",
        "X=np.linspace(0, 110000, 1000)\n",
        "plt.plot(X, t0 + t1*X, \"b:\")\n",
        "\n",
        "lin_reg_full = linear_model.LinearRegression()\n",
        "Xfull = np.c_[full_country_stats[\"GDP per capita\"]]\n",
        "yfull = np.c_[full_country_stats[\"Life satisfaction\"]]\n",
        "lin_reg_full.fit(Xfull, yfull)\n",
        "\n",
        "t0full, t1full = lin_reg_full.intercept_[0], lin_reg_full.coef_[0][0]\n",
        "X = np.linspace(0, 110000, 1000)\n",
        "plt.plot(X, t0full + t1full * X, \"k\")\n",
        "plt.xlabel(\"GDP per capita (USD)\")\n",
        "\n",
        "save_fig('representative_training_data_scatterplot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xRcMw2alo6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction', figsize=(8,3))\n",
        "plt.axis([0, 110000, 0, 10])\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import pipeline\n",
        "\n",
        "poly = preprocessing.PolynomialFeatures(degree=60, include_bias=False)\n",
        "scaler = preprocessing.StandardScaler()\n",
        "lin_reg2 = linear_model.LinearRegression()\n",
        "\n",
        "pipeline_reg = pipeline.Pipeline([('poly', poly), ('scal', scaler), ('lin', lin_reg2)])\n",
        "pipeline_reg.fit(Xfull, yfull)\n",
        "curve = pipeline_reg.predict(X[:, np.newaxis])\n",
        "plt.plot(X, curve)\n",
        "plt.xlabel(\"GDP per capita (USD)\")\n",
        "save_fig('overfitting_model_plot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_NocsPJlrth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_country_stats.loc[[c for c in full_country_stats.index if \"W\" in c.upper()]][\"Life satisfaction\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3fU6DM_lr7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdp_per_capita.loc[[c for c in gdp_per_capita.index if \"W\" in c.upper()]].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI6A4MgQlt7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,3))\n",
        "\n",
        "plt.xlabel(\"GDP per capita\")\n",
        "plt.ylabel('Life satisfaction')\n",
        "\n",
        "plt.plot(list(sample_data[\"GDP per capita\"]), list(sample_data[\"Life satisfaction\"]), \"bo\")\n",
        "plt.plot(list(missing_data[\"GDP per capita\"]), list(missing_data[\"Life satisfaction\"]), \"rs\")\n",
        "\n",
        "X = np.linspace(0, 110000, 1000)\n",
        "plt.plot(X, t0full + t1full * X, \"r--\", label=\"Linear model on all data\")\n",
        "plt.plot(X, t0 + t1*X, \"b:\", label=\"Linear model on partial data\")\n",
        "\n",
        "ridge = linear_model.Ridge(alpha=10**9.5)\n",
        "Xsample = np.c_[sample_data[\"GDP per capita\"]]\n",
        "ysample = np.c_[sample_data[\"Life satisfaction\"]]\n",
        "ridge.fit(Xsample, ysample)\n",
        "t0ridge, t1ridge = ridge.intercept_[0], ridge.coef_[0][0]\n",
        "plt.plot(X, t0ridge + t1ridge * X, \"b\", label=\"Regularized linear model on partial data\")\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.axis([0, 110000, 0, 10])\n",
        "plt.xlabel(\"GDP per capita (USD)\")\n",
        "save_fig('ridge_model_plot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS1-WxPtlv9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backup = oecd_bli, gdp_per_capita\n",
        "\n",
        "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
        "    return sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt8axDYVlyjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace this linear model:\n",
        "import sklearn.linear_model\n",
        "model = sklearn.linear_model.LinearRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sl4Y4K8l0fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with this k-neighbors regression model:\n",
        "import sklearn.neighbors\n",
        "model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmr927Mjl0vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.c_[country_stats[\"GDP per capita\"]]\n",
        "y = np.c_[country_stats[\"Life satisfaction\"]]\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make a prediction for Cyprus\n",
        "X_new = np.array([[22587.0]])  # Cyprus' GDP per capita\n",
        "print(model.predict(X_new)) # outputs [[ 5.76666667]]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}