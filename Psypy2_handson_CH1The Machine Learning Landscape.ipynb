{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helloKH/Psypy/blob/master/Psypy2_handson_CH1The%20Machine%20Learning%20Landscape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri7UWbxpYUPb",
        "colab_type": "code",
        "outputId": "bf29a7d1-5d35-4cbc-a417-8bb0fd6da728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/helloKH/Psypy.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Psypy'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/36)\u001b[K\rremote: Counting objects:   5% (2/36)\u001b[K\rremote: Counting objects:   8% (3/36)\u001b[K\rremote: Counting objects:  11% (4/36)\u001b[K\rremote: Counting objects:  13% (5/36)\u001b[K\rremote: Counting objects:  16% (6/36)\u001b[K\rremote: Counting objects:  19% (7/36)\u001b[K\rremote: Counting objects:  22% (8/36)\u001b[K\rremote: Counting objects:  25% (9/36)\u001b[K\rremote: Counting objects:  27% (10/36)\u001b[K\rremote: Counting objects:  30% (11/36)\u001b[K\rremote: Counting objects:  33% (12/36)\u001b[K\rremote: Counting objects:  36% (13/36)\u001b[K\rremote: Counting objects:  38% (14/36)\u001b[K\rremote: Counting objects:  41% (15/36)\u001b[K\rremote: Counting objects:  44% (16/36)\u001b[K\rremote: Counting objects:  47% (17/36)\u001b[K\rremote: Counting objects:  50% (18/36)\u001b[K\rremote: Counting objects:  52% (19/36)\u001b[K\rremote: Counting objects:  55% (20/36)\u001b[K\rremote: Counting objects:  58% (21/36)\u001b[K\rremote: Counting objects:  61% (22/36)\u001b[K\rremote: Counting objects:  63% (23/36)\u001b[K\rremote: Counting objects:  66% (24/36)\u001b[K\rremote: Counting objects:  69% (25/36)\u001b[K\rremote: Counting objects:  72% (26/36)\u001b[K\rremote: Counting objects:  75% (27/36)\u001b[K\rremote: Counting objects:  77% (28/36)\u001b[K\rremote: Counting objects:  80% (29/36)\u001b[K\rremote: Counting objects:  83% (30/36)\u001b[K\rremote: Counting objects:  86% (31/36)\u001b[K\rremote: Counting objects:  88% (32/36)\u001b[K\rremote: Counting objects:  91% (33/36)\u001b[K\rremote: Counting objects:  94% (34/36)\u001b[K\rremote: Counting objects:  97% (35/36)\u001b[K\rremote: Counting objects: 100% (36/36)\u001b[K\rremote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 343 (delta 19), reused 0 (delta 0), pack-reused 307\u001b[K\n",
            "Receiving objects: 100% (343/343), 3.65 MiB | 8.95 MiB/s, done.\n",
            "Resolving deltas: 100% (181/181), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lHI_h26Zdcn",
        "colab_type": "code",
        "outputId": "2b51ddfc-9f79-4695-8d3c-2a6537b5e960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls -ltr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Dec 18 16:52 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4096 Jan  1 22:17 \u001b[01;34mPsypy\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVw1d2-hYeEm",
        "colab_type": "code",
        "outputId": "2a2a015c-51e7-4f79-d45c-acf2878eba23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!ls Psypy/image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Figure 1-10.png'  'Figure 1-16.png'  'Figure 1-21.png'  'Figure 1-5.png'\n",
            "'Figure 1-11.png'  'Figure 1-17.png'  'Figure 1-22.png'  'Figure 1-6.png'\n",
            "'Figure 1-12.png'  'Figure 1-18.png'  'Figure 1-23.png'  'Figure 1-7.png'\n",
            "'Figure 1-13.png'  'Figure 1-19.png'  'Figure 1-2.png'\t 'Figure 1-8.png'\n",
            "'Figure 1-14.png'  'Figure 1-1.png'   'Figure 1-3.png'\t 'Figure 1-9.png'\n",
            "'Figure 1-15.png'  'Figure 1-20.png'  'Figure 1-4.png'\t  Read.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1E4tHPGYU54",
        "colab_type": "text"
      },
      "source": [
        "### Psypy2 1회차\n",
        "#### 교재: Hands on Machine Learning with Scikit-Learn, Keras & TensorFlow\n",
        "#### Part1. The Fundamentals of Machine Learning\n",
        "##### CH1. The Machine Learning Landscape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ9amP37YXMF",
        "colab_type": "text"
      },
      "source": [
        "#### Chapter1 목적\n",
        "- 모든 데이터 과학자가 알아야 하는 기본 개념 소개"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lenFcjT-YZi7",
        "colab_type": "text"
      },
      "source": [
        "### What Is Machine Learning?\n",
        "- Machine Learning is the science (and art) of programming computers so they can learn from data.\n",
        "\n",
        "- general definition  \n",
        "[Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed.  \n",
        "— Arthur Samuel, 1959\n",
        "\n",
        "\n",
        "- engineering  \n",
        "A computer program is said to learn from experience E with respect to some task Tand some performance measure P, if its performance on T, as measured by P, improves with experience E.  \n",
        "—Tom Mitchell, 1997"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr2wbXwQYbgy",
        "colab_type": "text"
      },
      "source": [
        "### Why Use Machine Learning?\n",
        "\n",
        "##### 1. 일반적인 스팸 분류 방법과 절차(그림1)\n",
        "\n",
        "\n",
        "![Figure1-1](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-1.png)\n",
        "\n",
        "1. 스팸 메일은 일반적으로 일부 문구(“4U,” “credit card,” “free,” and “amazing”)를 포함\n",
        "2. 발견 한 각 패턴에 대해 탐지 알고리즘을 작성하고 이러한 패턴이 다수 감지되면 프로그램은 이메일을 스팸으로 표시.\n",
        "3.  프로그램을 테스트하고 충분할 때까지 1 단계와 2 단계를 반복.\n",
        "\n",
        "##### 2. ML을 이용한 스팸 분류 방법과 절차(그림2)\n",
        "\n",
        "![Figure1-2](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-1.png)\n",
        "\n",
        "반대로 Machine Learning 기술을 기반의 스팸 필터는 스팸 예시에서 비정상적으로 빈번한 단어 패턴을 감지, 어떤 단어와 구가 스팸을 예측하는 좋은지 자동으로 학습 (그림 1-2).\n",
        "\n",
        "##### 3. 분류기 자동화(그림3) \n",
        "\n",
        "![Figure1-3](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-3.png)\n",
        "\n",
        "또한 “For U”와 같은 단어가 빈번하게 발생하면, 사용자의 지정 없이도 해당 단어를 스팸 분류기에 포함할 수 있음\n",
        "\n",
        "##### 4. 인간 학습에 도움을 주는 머신러닝(그림4)\n",
        "\n",
        "![Figure1-4](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-4.png)\n",
        "\n",
        "ML 알고리즘을 통한 학습은 인간이 의심하지 못한 상관관계나 새로운 경향을 보여줄 때가 있음. 이는 해당 문제를 더 잘 이해하게 도울 수 있다.\n",
        "\n",
        "\n",
        "요약하자면, 머신러닝은 아래와 같은 이점을 제공  \n",
        "* 기존 솔루션에 많은 수동 조정 또는 긴 규칙 목록이 필요한 문제 : 하나의 머신 러닝 알고리즘으로 종종 코드를 단순화하고 성능을 향상.  \n",
        "* 전통적인 방법을 사용하여 좋은 해결책이 전혀없는 복잡한 문제 : 머신 러닝 기술로 해결책 발견 가능  \n",
        "* 변동하는 환경 : 머신 러닝 시스템은 새로운 데이터에 적응 가능  \n",
        "* 복잡한 문제와 많은 양의 데이터에 대한 통찰력 제공 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsfCr1uG9Ywn",
        "colab_type": "text"
      },
      "source": [
        "### Types of Machine Learning Systems\n",
        "\n",
        "분류하는 몇 가지 기준 존재\n",
        "\n",
        "* 인간 감독 훈련을 받았는지 여부 (지도학습, 비지도학습, 반지도학습 및 강화학습)  \n",
        "* 즉석에서 점진적으로 학습 할 수 있는지 여부 (online vs batch learning)  \n",
        "* 과학자들이 하는 것처럼 새로운 데이터 포인트를 알려진 데이터 포인트와 단순히 비교하거나 대신 훈련 데이터의 패턴을 감지하고 예측 모델을 구축하여 작업하는지 여부 (instance-based versus model-based learning)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyNMaVsiW1Tf",
        "colab_type": "text"
      },
      "source": [
        "#### Supervised/Unsupervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E9l_oEx_XI_",
        "colab_type": "text"
      },
      "source": [
        "##### 1. Supervised learning\n",
        "\n",
        "알고리즘에 제공하는 training data에 label이라 불리는, solutions이 포함됨\n",
        "\n",
        "(1) classification  \n",
        "\n",
        "![Figure1-5](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-5.png)\n",
        "\n",
        "일반적인 지도학습의 예시는 분류(classification). 스팸 분류 사례 참고\n",
        "class (spam or ham)가 포함된 예제를 학습하면서, 새로운 대상이 스팸인지 아닌지를 분류한다.\n",
        "\n",
        "(2) Regression\n",
        "\n",
        "![Figure1-6](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-6.png)\n",
        "\n",
        "마일리지, 연령 등 숫자 값을 예측하는 경우, 회귀(Regression)라고 함.   \n",
        "training data에는 label(ex-가격)과 예측 변수(predictors)가 모두 포함됨\n",
        "\n",
        "* 단, 일부 회귀 모형 알고리즘(Logistic Regression 등)은 분류에 사용 가능\n",
        "\n",
        "\n",
        "이 책에서 다루는 강화학습의 주요 알고리즘은 아래와 같음\n",
        "* k-Nearest Neighbors\n",
        "* Linear Regression\n",
        "* Logistic Regression\n",
        "* Support Vector Machines (SVMs)\n",
        "* Decision Trees and Random Forests\n",
        "* Neural networks2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3ZYiAu2WyxE",
        "colab_type": "text"
      },
      "source": [
        "##### 2. Unsupervised learning\n",
        "\n",
        "![Figure1-7](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-7.png)\n",
        "\n",
        "학습(정답 label) 없이 진행되는 시스템\n",
        "\n",
        "가장 중요한 비지도학습 알고리즘은 아래와 같음(Chapter 8 & 9)\n",
        "* Clustering\n",
        "  - K-Means\n",
        "  - DBSCAN\n",
        "  - Hierarchical Cluster Analysis (HCA)\n",
        "* Anomaly detection and novelty detection\n",
        "  - One-class SVM\n",
        "  - Isolation Forest\n",
        "* Visualization and dimensionality reduction\n",
        "  - Principal Component Analysis (PCA)\n",
        "  - Kernel PCA\n",
        "  - Locally-Linear Embedding (LLE)\n",
        "  - t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
        "* Association rule learning\n",
        "  - Apriori\n",
        "  - Eclat\n",
        "\n",
        "\n",
        "(1) Clustering: 블로그 방문자 분석 예시  \n",
        "![Figure1-8](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-8.png)\n",
        "\n",
        "블로그 방문자에 대한 클러스터링 진행 가능. hierarchical clustering algorithm 등으로 세분화를 할 경우, 각 집단의 게시물을 타겟팅하는데 도움이 된다.\n",
        "\n",
        "(2) Visualization  \n",
        "![Figure1-9](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-9.png)\n",
        "\n",
        "complex and unlabeled data에 대해 2D or 3D representation을 출력\n",
        "\n",
        "시각화 알고리즘은 가능한 한 많은 구조를 유지하려고 함(예 : 입력 공간에서 별도의 클러스터를 시각화에서 겹치지 않도록 유지하려고 시도함). 따라서 데이터의 구성 방식을 이해하고 의심되지 않는 패턴을 식별할 수 있다.\n",
        "\n",
        "차원 축소(dimensionality reduction)는 이와 관련되는 작업으로, 너무 많은 데이터 손실 없이 데이터를 단순화하는 것을 일컫음. 이를 수행하는 방법으로 기능추출(feature extraction)이 존재\n",
        "- 예) 자동차의 주행 거리는 나이와 관련이 있기 때문에, 이 2가지를 자동차의 마모를 나타내는 기능으로 병합함\n",
        "\n",
        "(3) 이상 탐지(anomaly detection)\n",
        "\n",
        "신용 카드에서 사기 거래 감지, 제조 결함 포착 등.  \n",
        "![Figure1-10](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-10.png)\n",
        "\n",
        "시스템은 training 과정에서 정상 사례(normal instances)를 학습하고, 새 instances가 들어올 때 그것의 정상/비정상 여부를 판단 \n",
        "새로움 탐지(novelty detection) 역시 비슷한 과정. 단 novelty detection는 training 중에 정상적인 데이터만 예상하는 반면, 이상탐지 알고리즘은 적은 비율의 이상치로도 우수한 성능 가능. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKbRYDVtwa3M",
        "colab_type": "text"
      },
      "source": [
        "##### 3. Semisupervised learning\n",
        "\n",
        "몇몇 알고리즘은 부분적으로는 label이 있는 training data를 사용함과 동시에  unlabeled data도 사용 가능.(그림 1-11).\n",
        "\n",
        "![Figure1-11](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-11.png)\n",
        "\n",
        "- 예) 구글 photo와 같은 사진 호스팅 서비스\n",
        "- 모든 가족 사진을 서비스에 업로드하면 동일한 사람 A가 사진 1, 5 및 11에 표시되고 다른 사람 B가 사진 2, 5 및 7에 표시되는 것을 자동으로 인식하게 됨(지도되지 않은 부분, 클러스터링). 이후 한 사람당 하나의 레이블로 모든 사진의 모든 사람의 이름을 지정하여 검색하게 함.\n",
        "\n",
        "대부분의 Semisupervised learning는 지도학습과 비지도학습 알고리즘의 조합임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCaodpJM43aT",
        "colab_type": "text"
      },
      "source": [
        "##### 4. Reinforcement Learning\n",
        "\n",
        "![Figure1-12](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-12.png)\n",
        "\n",
        "- agent라 불리는 학습 시스템은 환경을 관찰할 수 있으며, 이후 action을 선택 및 수행한 후 그에 대한 보상(혹은 처벌)을 받음 \n",
        "\n",
        "ex) DeepMind’s AlphaGo program\n",
        "- 수백만 개의 게임을 분석한 후 자기 자신과 대결하며 스스로 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSrbEFJU5_Mz",
        "colab_type": "text"
      },
      "source": [
        "#### Batch and Online Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntZX2CDV6O69",
        "colab_type": "text"
      },
      "source": [
        "##### 1. Batch learning\n",
        "Batch learning은 점진적으로(incrementally) 학습할 수 없음. 사용 가능한 모든 데이터를 사용하여 학습해야 한다는 특징 존재. 많은 시간과 computing resource 요구.\n",
        "\n",
        "시스템 training 후 더 이상의 학습(learning) 없이 바로 투입되는 형태를 offline learning이라고 함.\n",
        "\n",
        "##### 2. Online learning\n",
        "\n",
        "Online learning에서는 데이터 instance를 개별적으로 혹은 소그룹(mini-batches)으로 순차적으로 공급하여 시스템을 점진적으로 훈련시킴. 각 학습 단계는 빠르고 저렴하므로 시스템은 새로운 데이터가 도착하자마자 즉시 학습 가능(그림 1-13).\n",
        "\n",
        "![Figure1-13](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-13.png)\n",
        "\n",
        "Online learning은 데이터를 지속적인 흐름(예 : 주가)으로 받고 빠르게/자율적으로 변화에 적응해야하는 시스템에 적합.\n",
        "\n",
        "computing resources가 제한될 경우, online learning system이 instance을 알게 되고 더 이상 필요 없다면 버릴 수 있음. 이는 엄청난 양의 공간을 절약함.\n",
        "\n",
        "![Figure1-14](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-14.png)\n",
        "\n",
        "온라인 학습 알고리즘을 사용하여 한 시스템의 기본 메모리에 맞지 않는 방대한 데이터 세트에 대한 시스템을 교육 할 수도 있다 (out-of-core learning). 알고리즘은 데이터의 일부를 load하고 해당 데이터에 대한 training step를 실행하며, 모든 데이터에서 실행될 때까지 프로세스를 반복한다(그림 1-14 참조).\n",
        "\n",
        "온라인 학습 시스템의 중요한 parameter는 학습 속도(learning rate)-변화하는 데이터에 얼마나 빨리 적응하느냐-임. \n",
        "- 높은 학습 속도 = 시스템이 새로운 데이터에 빠르게 적응하지만 이전 데이터를 빠르게 잊어 버린다(스팸 필터가 표시된 최신 스팸만 표시하고, 전체 스팸 필터를 원하지 않음) .\n",
        "- 낮은 학습 속도 = 시스템의 관성이 높아짐. 즉, 학습 속도가 느려지지만 새 데이터의 노이즈나 대표성이 없는 데이터포인트(이상치)의 시퀀스에 덜 민감함.\n",
        "\n",
        "온라인 학습의 가장 큰 문제는 잘못된 데이터가 시스템에 제공될 경우, 시스템 성능이 점차 저하된다는 것. 이 위험을 줄이려면 성능 저하가 감지될 때 시스템을 모니터링하고, 학습을 해제하고, 이전 상태로 되돌릴 수 있어야 한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCNhWliLa87Y",
        "colab_type": "text"
      },
      "source": [
        "#### Instance-Based Versus Model-Based Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXSXDVAGh3op",
        "colab_type": "text"
      },
      "source": [
        "##### 1. Instance-based learning\n",
        "\n",
        "시스템은 예제를 중심으로 학습한 다음 유사성 측정을 사용하여 학습된 예제(또는 subset)와 비교하여 새 사례로 일반화\n",
        "\n",
        "![Figure1-15](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-15.png)\n",
        "\n",
        "예를 들어 그림 1-15에서 가장 유사한 instance의 대부분이 삼각형 클래스에 속하므로 새 인스턴스는 삼각형으로 분류\n",
        "\n",
        "##### 2. Model-based learning\n",
        "\n",
        "![Figure1-16](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-16.png)\n",
        "\n",
        "예제의 모델을 형성한 후 해당 모델을 사용하여 예측을 진행\n",
        "\n",
        "![Figure1-17](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-17.png)\n",
        "\n",
        "예를 들어, 돈이 사람들을 행복하게하는지 알고 싶어서 OECD 웹 사이트에서 Better Life Index 데이터와 IMF 웹 사이트에서 1 인당 GDP에 대한 통계를 다운로드한다고 가정.\n",
        "\n",
        "국가의 1인당 GDP가 증가함에 따라 삶의 만족도가 선형적으로 증가하는 것처럼 보이므로, 1인당 GDP의 선형 함수로 삶의 만족도를 예측하는 모델 생성(model selection) 가능.\n",
        "\n",
        "1개의 속성(GDP per capita)으로 삶의 만족도를 예측하는 방정식:\n",
        "\n",
        "$$life  satisfaction = θ0 + θ1 × GDP per capita$$\n",
        "\n",
        "![Figure1-18](https://raw.githubusercontent.com/helloKH/Psypy/master/image/Figure%201-18.png)\n",
        "\n",
        "2개의 모델 파라미터(θ0 + θ1)로 선형함수를 표현 가능(그림 1-18)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0w1EGLn_X_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}